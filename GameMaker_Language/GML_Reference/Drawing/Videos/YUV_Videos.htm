<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><script type="text/javascript" src="../../../../assets/import/jquery-3.6.1.min.js"></script><script type="text/javascript" src="../../../../assets/import/layer/layer.js"></script><script type="text/javascript" src="../../../../assets/import/pangu.min.js"></script><link rel="stylesheet" type="text/css" href="../../../../assets/import/layer/layui_btn.css"><link rel="stylesheet" type="text/css" href="../../../../assets/import/layer/layui_col.css"><link rel="stylesheet" type="text/css" href="../../../../assets/import/layer/theme/default/layer.css"><link rel="stylesheet" type="text/css" href="../../../../assets/import/main.css"><script>let str;removeHtml=function(e){return e=(e=(e=(e=e.replace(/(<([^>]+)>)/gi,"{}")).replace(/\r\n/g,"\n")).replace(/\n/g,"")).replace(/ {2,}/g," ")},retHtml=function(e){return e.match(/(<([^>]+)>)/gi)},setTranslator=function(e,t,a){let n;n=a?e.attr(a):e.html();let r=t[removeHtml(n)];if(null!=r&&r.length){t=retHtml(n);let o=0;t&&t.forEach(function(e,t){var a=r.replace("{"+o+"}",e);r=a===r?r.replace("{}",e):a,o++}),a?e.attr(a,r):e.html(r)}},noTranslationState=function(){return"true"==window.localStorage.getItem("noTranslationState")},noTranslationStateToggle=function(){window.localStorage.setItem("noTranslationState",!noTranslationState())},addNoTranslationStateButton=function(){var e=`
		
		<button style="
			float: right;
			font-size: 16px;
			padding: 4px 12px;
		"
		onclick="
		window.location.replace('gmmt://'+document.location.hash)
		"
		>打开编辑器</button>

		<button style="
			float: right;
			font-size: 16px;
			padding: 4px 12px;
		"
		onclick="
		noTranslationStateToggle();
		location.reload();
    	event.stopPropagation();
		"
		>切换翻译</button>
		`;$(".header").length?$(".header").append(e):($(".topic-header").append(e),$(".topic-header button").css("position","relative").css("top","44px"))},removeExtensionFromHash=function(e){return e.replaceAll("#t=","").replaceAll("%2F","/").replaceAll(".htm","")};let json_global,json_file={"Create a shader asset in your project, and replace its Fragment Shader ({}.fsh{}) code with this:":"在项目中创建着色器资源，并将其碎片着色器 ({}.fsh{}) 代码替换为：","Draw Video":"绘制视频","Get Sampler":"获取采样器","Gets the video surface ({}_surf{}) and the chroma surface ({}_chromasurf{})":"获取视频表面({}_surface{})和色度表面({}_chromasurf{})","Here the main video surface is being drawn by the primitive, and the chroma surface is being blended on to it by the shader. That is the reason why the texture of the chroma surface was passed into the shader via a sampler.":"这里，主视频表面由基本体绘制，色度表面通过着色器与其混合。这就是为什么通过采样器将色度表面的纹理传递到着色器的原因。","If the video is using the YUV format, it uses the shader to draw the two surfaces (in positions {}[1]{} and {}[2]{}) onto a primitive quad.":"如果视频使用 YUV 格式，则使用着色器将两个表面 (位置 {}[1]{} 和 {}[2]{}) 绘制到基本体四边形上。","In the Create event of your object, get the sampler ID of the {}v_chroma{} shader uniform, only if the video is YUV:":"在创建对象事件中，获取{}v_chroma{}着色器制服的采样器ID(仅当视频为 YUV  时)：","In the Draw event of your object, call {}{}video_draw(){}{}, and if its first array position is {}0{} (meaning the video is playing), draw the video.":'在对象的"绘制"事件中，调用{}{}video_draw(){}{}，如果其第一个数组位置为{}0{}(表示正在播放视频)，请绘制视频。',"In the code below, we're using a switch statement on the {}{}video_get_format(){}{} function. If the video is using the RGBA format, then it simply draws the surface in position {}[1]{} of the array.":"在下面的代码中，我们在 {}{}video_get_format(){}{} 函数上使用 switch 语句。如果视频使用的是 RGBA 格式，则它只是在阵列的 {}[1]{} 位置绘制表面。","Makes sure that they exist, using {}{}surface_exist(){}{} {} {}Sets the shader to {}shader_YUV{} (which is our newly created YUV shader){} {}Gets the textures of both surfaces{} {}Assigns the texture of the chroma surface to the sampler we retrieved in the Create event{} {}Disables texture filtering{} {}Begins drawing a triangle strip primitive, with the video surface's texture assigned to it{} {}Draws a rectangle to cover the video surface, uses the width and height of the chroma surface for that rectangle{} {}Ends the primitive{} {}Re-enables texture filtering and resets the shader{} {} ":'使用{}{}surface_exist(){}{}确保它们存在{}{}将着色器设置为{}shader_ YUV  {}(这是我们新创建的 YUV  着色器){}{}获取两个表面的纹理{}{}将色度表面的纹理指定给在"Create"事件中检索到的采样器{}{}禁用纹理过滤{}{}开始绘制三角形条纹基本体，并将视频表面的纹理指定给它{}{}绘制一个矩形以覆盖视频表面，使用该矩形的色度表面的宽度和高度{}{}结束原语{}{}重新启用纹理过滤并重置着色器{}{}',"Platforms that use the YUV colour format for videos require extra steps for drawing those videos. This involves using a shader to draw two surfaces on a primitive quad.":"对于视频使用YUV颜色格式的平台，需要额外的步骤来绘制这些视频。这涉及到使用着色器在基本体四边形上绘制两个表面。","Read the {}{}video_draw(){}{} reference page first for information on what data that function returns for YUV videos, and then continue reading below for instructions on using that data to draw the video.":"首先阅读{}{}video_draw(){}{}参考页，了解有关函数为 YUV  视频返回的数据的信息，然后继续阅读下面的内容，了解有关使用该数据绘制视频的说明。","Sets the shader to {}shader_YUV{} (which is our newly created YUV shader)":"将着色器设置为{}shader_ YUV  {}(这是我们新创建的 YUV  着色器)","The code under {}case video_format_yuv:{} does the following:":"{}case video_format_yuv:{}下的代码执行以下操作：","YUV Shader":"YUV 着色器","YUV Videos":"YUV 视频","将着色器设置为{}shader_ YUV {}(这是我们新创建的 YUV 着色器)":"将着色器设置为 {}shader_YUV{}( 这是我们新创建的 YUV 着色器)"},get_json_global=$.ajax({url:"/global.json",type:"GET",dataType:"json",async:!1,success:function(e){json_global=e}});$(function(){if(addNoTranslationStateButton(),noTranslationState())return!1;$("div.footer a,h4,caption").each(function(){setTranslator($(this),json_global)}),$("p,h1,h2,h3,td,li,a,div.dropspotnote,figcaption").each(function(){setTranslator($(this),json_file)}),$("th,.warning,.important,.optional").each(function(){setTranslator($(this),json_global)}),$(".header").length&&(window.setInterval(function(){$("#toc-panel a:not('isTranslate')").each(function(){$(this).addClass("isTranslate"),setTranslator($(this),json_global)}),$(".GlossDefinitionText:not('isTranslate')").each(function(){$(this).addClass("isTranslate"),setTranslator($(this),json_global)})},250),console.log("成功啦!现在正在疯狂翻译菜单中!")),$(".tooltip").each(function(){setTranslator($(this),json_global,"title")})}),document.addEventListener("DOMContentLoaded",()=>{pangu.autoSpacingPage()})</script><script type="text/javascript" language="JavaScript">function reDo(){innerWidth==origWidth&&innerHeight==origHeight||location.reload()}4==parseInt(navigator.appVersion)&&"Netscape"==navigator.appName&&(origWidth=innerWidth,origHeight=innerHeight,onresize=reDo),onerror=null</script><style type="text/css">p.WebHelpNavBar{text-align:right}</style><script type="text/javascript">gCommonRootRelPath=gRootRelPath="../../../..",gTopicId="8.2.2.6.12.0_4"</script><script type="text/javascript" src="../../../../template/scripts/rh.min.js"></script><script type="text/javascript" src="../../../../template/scripts/common.min.js"></script><script type="text/javascript" src="../../../../template/scripts/topic.min.js"></script><script type="text/javascript" src="../../../../template/scripts/topicwidgets.min.js"></script><script type="text/javascript" src="../../../../whxdata/projectsettings.js"></script><link rel="stylesheet" type="text/css" href="../../../../template/styles/topic.min.css"><link rel="stylesheet" type="text/css" href="../../../../template/Charcoal_Grey/topicheader.css"><meta name="topic-status" content="Draft"><link rel="stylesheet" type="text/css" href="../../../../assets/css/default.css"><script src="../../../../../assets/scripts/main_script.js"></script><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="generator" content="Adobe RoboHelp 2022"><title>YUV Videos</title><meta name="topic-status" content="Draft"><link rel="stylesheet" type="text/css" href="../../../../assets/css/default.css"><script src="../../../../assets/scripts/main_script.js" type="module"></script><meta name="rh-authors" content="Gurpreet S. Matharoo"><meta name="topic-comment" content="Information on drawing YUV videos"><meta name="template" content="../../../../assets/masterpages/Manual_Page.htt"><meta name="rh-index-keywords" content="yuv videos"><meta name="search-keywords" content="yuv videos"><meta name="condition-tags" content=""><meta name="brsnext" value="GameMaker_Language/GML_Reference/Drawing/Videos/video_set_volume.htm"><meta name="brsprev" value="GameMaker_Language/GML_Reference/Drawing/Videos/video_draw.htm"></head><body><div class="topic-header rh-hide" id="rh-topic-header"><div class="logo"></div><div class="nav"><div class="title" title="YUV Videos"><span>YUV Videos</span></div><div class="gotohome" title="Click here to see this page in full context"><a href="#" onclick="rh._.goToFullLayout()">Click here to see this page in full context</a></div></div></div><div class="topic-header-shadow rh-hide" id="rh-topic-header-shadow"></div><div></div><div><h1>YUV Videos</h1><p>Platforms that use the YUV colour format for videos require extra steps for drawing those videos. This involves using a shader to draw two surfaces on a primitive quad.</p><p>Read the <span class="inline"><a href="video_draw.htm">video_draw()</a></span> reference page first for information on what data that function returns for YUV videos, and then continue reading below for instructions on using that data to draw the video.</p><h2>YUV Shader</h2><p>Create a shader asset in your project, and replace its Fragment Shader (<span class="inline2">.fsh</span>) code with this:</p><pre>//
// CUSTOM fragment shader for handling YUV content
//
varying vec2 v_vTexcoord;
varying vec4 v_vColour;
uniform sampler2D v_chroma;
const float x = 1.164383;
const float y = 1.138393;
const float z = 1.138393;
const vec3 src_bias = vec3(16.0 / 255.0, 128.0 / 255.0, 128.0 / 255.0);
const mat3 src_xform = mat3(1.00000000 * x,  0.00000000 * y,  1.57480000 * z,
                            1.00000000 * x, -0.18732427 * y, -0.46812427 * z,
			    1.00000000 * x,  1.85560000 * y,  0.00000000 * z);
void main()
{
    float yy = texture2D(gm_BaseTexture, vec2(v_vTexcoord.x, v_vTexcoord.y)).r;
    vec2 cbcr = texture2D(v_chroma, vec2(v_vTexcoord.x, v_vTexcoord.y)).rg;
    vec3 yuv = vec3(yy, cbcr);
    yuv -= src_bias;
    yuv *= src_xform;
    gl_FragColor = vec4(yuv, 1.0);
}
  
</pre><h2>Get Sampler</h2><p>In the Create event of your object, get the sampler ID of the <span class="inline2">v_chroma</span> shader uniform, only if the video is YUV:</p><pre>var _format = video_get_format();
if (_format == video_format_yuv)
{
    videochromasampler = shader_get_sampler_index(shader_YUV, "v_chroma");
}
</pre><h2 id="h">Draw Video</h2><p>In the Draw event of your object, call <span class="inline"><a href="video_draw.htm">video_draw()</a></span>, and if its first array position is <strong>0</strong> (meaning the video is playing), draw the video.</p><p>In the code below, we're using a switch statement on the <span class="inline"><a href="video_get_format.htm">video_get_format()</a></span> function. If the video is using the RGBA format, then it simply draws the surface in position <span class="inline2">[1]</span> of the array.</p><p>If the video is using the YUV format, it uses the shader to draw the two surfaces (in positions <span class="inline2">[1]</span> and <span class="inline2">[2]</span>) onto a primitive quad.</p><pre>var _data = video_draw();
if(_data[0] == 0)
{
	switch(video_get_format())
	{
		case video_format_rgba:
			var _surf = _data[1];
			draw_surface(_surf,0,0);
		break;
	
		//  #### YUV PART HERE ####
		case video_format_yuv:
			var _surf = _data[1];
			var _chromasurf = _data[2];
			if(surface_exists(_surf) and surface_exists(_chromasurf))
			{
				shader_set(shader_YUV);
			
				var _tex_id = surface_get_texture(_surf);
				var _chroma_tex_id = surface_get_texture(_chromasurf);
				texture_set_stage(videochromasampler, _chroma_tex_id);
				gpu_set_texfilter(false);
			
				draw_primitive_begin_texture(pr_trianglestrip, _tex_id);
			        draw_vertex_texture(0, 0, 0, 0);
				draw_vertex_texture(surface_get_width(_chromasurf), 0, 1, 0);
				draw_vertex_texture(0, surface_get_height(_chromasurf), 0, 1);
				draw_vertex_texture(surface_get_width(_chromasurf), surface_get_height(_chromasurf), 1, 1);
				draw_primitive_end();
			
				gpu_set_texfilter(true);
				shader_reset();
			}
		break;
	}
}
  </pre><p>The code under <span class="inline2">case video_format_yuv:</span> does the following:</p><ul class="colour"><li>Gets the video surface (<span class="inline2">_surf</span>) and the chroma surface (<span class="inline2">_chromasurf</span>)</li><li>Makes sure that they exist, using <span class="inline"><a href="../Surfaces/surface_exists.htm">surface_exist()</a></span><ul><li>Sets the shader to <span class="inline2">shader_YUV</span> (which is our newly created YUV shader)</li><li>Gets the textures of both surfaces</li><li>Assigns the texture of the chroma surface to the sampler we retrieved in the Create event</li><li>Disables texture filtering</li><li>Begins drawing a triangle strip primitive, with the video surface's texture assigned to it</li><li>Draws a rectangle to cover the video surface, uses the width and height of the chroma surface for that rectangle</li><li>Ends the primitive</li><li>Re-enables texture filtering and resets the shader</li></ul></li></ul><p>Here the main video surface is being drawn by the primitive, and the chroma surface is being blended on to it by the shader. That is the reason why the texture of the chroma surface was passed into the shader via a sampler.</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><div class="footer"><div class="buttons"><div class="clear"><div>Back:&nbsp;<a href="Videos.htm#h1">Video Playback</a></div><div>Next:&nbsp;<a href="video_set_volume.htm">video_set_volume</a></div></div></div><h5><span data-keyref="Copyright Notice">© Copyright YoYo Games Ltd. 2024 All Rights Reserved</span></h5></div></div></body></html>